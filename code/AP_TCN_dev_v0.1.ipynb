{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import io as sio\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# TCN imports \n",
    "import tf_models, ap_datasets, utils, metrics\n",
    "from utils import imshow_\n",
    "\n",
    "# ---------- Directories & User inputs --------------\n",
    "# Location of data/features folder\n",
    "base_dir = os.path.expanduser(\"../\")\n",
    "\n",
    "save_predictions = [False, True][1]\n",
    "viz_predictions = [False, True][1]\n",
    "viz_weights = [False, True][0]\n",
    "\n",
    "# Set dataset and action label granularity (if applicable)\n",
    "dataset = [\"50Salads\", \"JIGSAWS\", \"MERL\", \"GTEA\"][0]\n",
    "granularity = [\"eval\", \"mid\"][1]\n",
    "sensor_type = [\"video\", \"sensors\"][0]\n",
    "\n",
    "# Set model and parameters\n",
    "model_type = [\"ED-TCN\",\"AP-TCN\"][1]\n",
    "# causal or acausal? (If acausal use Bidirectional LSTM)\n",
    "causal = [False, True][0]\n",
    "\n",
    "# How many latent states/nodes per layer of network\n",
    "# Only applicable to the TCNs. The ECCV and LSTM  model suses the first element from this list.\n",
    "n_nodes = [64, 96]\n",
    "nb_epoch = 50 #200\n",
    "video_rate = 3\n",
    "conv = {'50Salads':25, \"JIGSAWS\":20, \"MERL\":5, \"GTEA\":25}[dataset]\n",
    "\n",
    "# Which features for the given dataset\n",
    "features = \"SpatialCNN\"\n",
    "bg_class = 0 if dataset is not \"JIGSAWS\" else None\n",
    "\n",
    "if dataset == \"50Salads\":\n",
    "    features = \"SpatialCNN_\" + granularity\n",
    "\n",
    "data = ap_datasets.Dataset(dataset, base_dir)\n",
    "trial_metrics = metrics.ComputeMetrics(overlap=.1, bg_class=bg_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AP TCN...\n",
      "> \u001b[0;32m<ipython-input-2-d93b89ca954a>\u001b[0m(105)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    103 \u001b[0;31m            \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    104 \u001b[0;31m            \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 105 \u001b[0;31m            \u001b[0mM_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    106 \u001b[0;31m            \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    107 \u001b[0;31m\u001b[0;31m#             model.fit(X_train_m, Y_train_, nb_epoch=nb_epoch, batch_size=8, verbose=1, sample_weight=M_train[:,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d93b89ca954a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mM_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m#             model.fit(X_train_m, Y_train_, nb_epoch=nb_epoch, batch_size=8, verbose=1, sample_weight=M_train[:,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jinchoi/anaconda2/envs/tf-ap/lib/python2.7/site-packages/Keras-1.2.1-py2.7.egg/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jinchoi/anaconda2/envs/tf-ap/lib/python2.7/site-packages/Keras-1.2.1-py2.7.egg/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jinchoi/anaconda2/envs/tf-ap/lib/python2.7/site-packages/Keras-1.2.1-py2.7.egg/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1918\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1920\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1921\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   1922\u001b[0m                               feed_dict=feed_dict)\n",
      "\u001b[0;32m/home/jinchoi/anaconda2/envs/tf-ap/lib/python2.7/site-packages/Keras-1.2.1-py2.7.egg/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=nb_thread,\n\u001b[1;32m    117\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jinchoi/anaconda2/envs/tf-ap/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \"\"\"\n\u001b[0;32m-> 1186\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jinchoi/anaconda2/envs/tf-ap/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewDeprecatedSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteSessionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import Pdb # for debugging, jinchoi@vt.edu\n",
    "pdb = Pdb()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Evaluate using different filter lengths\n",
    "if 1:\n",
    "# for conv in [5, 10, 15, 20]:\n",
    "    # Initialize dataset loader & metrics\n",
    "    data = ap_datasets.Dataset(dataset, base_dir)\n",
    "    trial_metrics = metrics.ComputeMetrics(overlap=.1, bg_class=bg_class)\n",
    "\n",
    "    split_cnt = 0\n",
    "    accuracies = np.zeros(len(data.splits))\n",
    "    # Load data for each split\n",
    "    for split in data.splits:\n",
    "        if sensor_type==\"video\":\n",
    "            feature_type = \"A\" if model_type != \"SVM\" else \"X\"\n",
    "        else:\n",
    "            feature_type = \"S\"\n",
    "\n",
    "        X_train, y_train, X_test, y_test = data.load_split(features, split=split, \n",
    "                                                            sample_rate=video_rate, \n",
    "                                                            feature_type=feature_type)\n",
    "\n",
    "        if trial_metrics.n_classes is None:\n",
    "            trial_metrics.set_classes(data.n_classes)\n",
    "\n",
    "        n_classes = data.n_classes\n",
    "        train_lengths = [x.shape[0] for x in X_train]\n",
    "        test_lengths = [x.shape[0] for x in X_test]\n",
    "\n",
    "        n_train = len(X_train)\n",
    "        n_test = len(X_test)\n",
    "\n",
    "        n_feat = data.n_features\n",
    "\n",
    "        # --------- CVPR model ----------\n",
    "        if model_type in [\"tCNN\", \"ED-TCN\", \"DilatedTCN\", \"TDNN\", \"AP-TCN\"]:\n",
    "            # Go from y_t = {from 1 to C} to one-hot vector (e.g. y_t = [0, 0, 1, 0])\n",
    "            #Y_train = [np_utils.to_categorical(y, n_classes) for y in y_train]\n",
    "            #Y_test = [np_utils.to_categorical(y, n_classes) for y in y_test]\n",
    "           \n",
    "            labels = list()\n",
    "            X_train_f = list()\n",
    "            num_frames = 0\n",
    "            num_actions = 0\n",
    "            for i in range(len(y_train)):\n",
    "                tmp = np.array(data.split_actions(y_train[i]))\n",
    "\n",
    "                if i >= 1:\n",
    "                    labels = np.vstack([labels,tmp])\n",
    "                else:\n",
    "                    labels = tmp;\n",
    "                for j in range(len(tmp)):\n",
    "                    X_train_f.append(X_train[i][tmp[j,1]:tmp[j,2]+1])\n",
    "                    num_frames += len(X_train[i][tmp[j,1]:tmp[j,2]+1])\n",
    "                    num_actions += 1\n",
    "                    \n",
    "            Y_train = [np_utils.to_categorical(y, n_classes) for y in labels[:,0]]\n",
    "            \n",
    "            labels = list()\n",
    "            X_test_f = list()\n",
    "            num_frames = 0\n",
    "            num_actions = 0\n",
    "            for i in range(len(y_test)):\n",
    "                tmp = np.array(data.split_actions(y_test[i]))\n",
    "\n",
    "                if i >= 1:\n",
    "                    labels = np.vstack([labels,tmp])\n",
    "                else:\n",
    "                    labels = tmp;\n",
    "                for j in range(len(tmp)):\n",
    "                    X_test_f.append(X_test[i][tmp[j,1]:tmp[j,2]+1])\n",
    "                    num_frames += len(X_test[i][tmp[j,1]:tmp[j,2]+1])\n",
    "                    num_actions += 1\n",
    "                    \n",
    "            Y_test = [np_utils.to_categorical(y, n_classes) for y in labels[:,0]]\n",
    "            y_test_ = [np.array([labels[:,0][i]]) for i in range(len(labels[:,0]))]\n",
    "            \n",
    "            # In order process batches simultaneously all data needs to be of the same length\n",
    "            # So make all same length and mask out the ends of each.\n",
    "            n_layers = len(n_nodes)\n",
    "            max_len = max(np.max(train_lengths), np.max(test_lengths))\n",
    "            max_len = int(np.ceil(max_len / (2**n_layers)))*2**n_layers\n",
    "            \n",
    "            max_len = 120 #128 # this should be elaborated\n",
    "        \n",
    "#            pdb.set_trace()\n",
    "            X_train_m, Y_train_, M_train = utils.mask_data(X_train_f, Y_train, max_len, mask_value=-1)\n",
    "            X_test_m, Y_test_, M_test = utils.mask_data(X_test_f, Y_test, max_len, mask_value=-1)\n",
    "            \n",
    "            Y_train_ = np.array(Y_train)            \n",
    "            Y_test_ = np.array(Y_test)\n",
    "            \n",
    "            if model_type == \"ED-TCN\":\n",
    "                model, param_str = tf_models.ED_TCN(n_nodes, conv, n_classes, n_feat, max_len, causal=causal, activation='norm_relu', return_param_str=True) \n",
    "            elif model_type == \"AP-TCN\":\n",
    "                print 'Training AP TCN...'\n",
    "                model, param_str = tf_models.AP_TCN(n_nodes, conv, n_classes, n_feat, max_len, causal=causal, \n",
    "                                        activation='norm_relu', return_param_str=True)               \n",
    "            \n",
    "            # summarize the model connection and compilation\n",
    "            #model.summary()\n",
    "            pdb.set_trace()\n",
    "            M_train2 = np.array([[1] for i in range(len(X_train_m))])\n",
    "            model.fit(X_train_m, Y_train_, nb_epoch=nb_epoch, batch_size=8, verbose=1, sample_weight=M_train2) \n",
    "#             model.fit(X_train_m, Y_train_, nb_epoch=nb_epoch, batch_size=8, verbose=1, sample_weight=M_train[:,0]) \n",
    "            \n",
    "            print(\"1\")\n",
    "            AP_train = model.predict(X_train_m, verbose=0)\n",
    "            print(\"2\")\n",
    "            AP_test = model.predict(X_test_m, verbose=0)\n",
    "            print(\"3\")\n",
    "            \n",
    "            P_train = [p.argmax(1) for p in AP_train]\n",
    "            P_test = [p.argmax(1) for p in AP_test]\n",
    " \n",
    "        else:\n",
    "            print(\"Model not available:\", model_type)\n",
    "\n",
    "        param_str = \"_\".join([granularity, sensor_type, param_str])\n",
    "        print(param_str)\n",
    "\n",
    "        # --------- Metrics ----------    \n",
    "        #trial_metrics.add_predictions(split, P_test, y_test)       \n",
    "        #trial_metrics.add_predictions(split, P_test, y_test_)       \n",
    "        #trial_metrics.print_trials()\n",
    "        #print()\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in range(len(P_test)):\n",
    "            if P_test[i][0] == y_test_[i][0]:\n",
    "                cnt += 1\n",
    "        accuracy = float(cnt)/len(P_test)\n",
    "\n",
    "        print accuracy\n",
    "        \n",
    "        accuracies[split_cnt] = accuracy\n",
    "        split_cnt += 1\n",
    "        \n",
    "    print 'Mean accuracy: {0}'.format(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "   # ----- Save predictions -----\n",
    "        if save_predictions:\n",
    "            dir_out = os.path.expanduser(base_dir+\"/predictions/{}/{}/\".format(dataset,param_str))\n",
    "\n",
    "            # Make sure folder exists\n",
    "            if not os.path.isdir(dir_out):\n",
    "                os.makedirs(dir_out)\n",
    "\n",
    "            out = {\"P\":P_test, \"Y\":y_test, \"S\":AP_test}\n",
    "            sio.savemat( dir_out+\"/{}.mat\".format(split), out)      \n",
    "\n",
    "        # ---- Viz predictions -----\n",
    "        if viz_predictions:\n",
    "            max_classes = data.n_classes - 1\n",
    "            # # Output all truth/prediction pairs\n",
    "            plt.figure(split, figsize=(20,10))\n",
    "            P_test_ = np.array(P_test)/float(n_classes-1)\n",
    "            y_test_ = np.array(y_test)/float(n_classes-1)\n",
    "            for i in range(len(y_test)):\n",
    "                P_tmp = np.vstack([y_test_[i], P_test_[i]])\n",
    "                plt.subplot(n_test,1,i+1); imshow_(P_tmp, vmin=0, vmax=1)\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                acc = np.mean(y_test[i]==P_test[i])*100\n",
    "                plt.ylabel(\"{:.01f}\".format(acc))\n",
    "                # plt.title(\"Acc: {:.03}%\".format(100*np.mean(P_test[i]==y_test[i])))\n",
    "\n",
    "        # ---- Viz weights -----\n",
    "        if viz_weights and model_type is \"TCN\":\n",
    "            # Output weights at the first layer\n",
    "            plt.figure(2, figsize=(15,15))\n",
    "            ws = model.get_weights()[0]\n",
    "            for i in range(min(36, len(ws.T))):\n",
    "                plt.subplot(6,6,i+1)\n",
    "                # imshow_(model.get_weights()[0][i][:,:,0]+model.get_weights()[1][i])\n",
    "                imshow_(np.squeeze(ws[:,:,:,i]).T)\n",
    "                # Output weights at the first layer\n",
    "\n",
    "            for l in range(2*n_layers):\n",
    "                plt.figure(l+1, figsize=(15,15))\n",
    "                ws = model.get_weights()[l*2]\n",
    "                for i in range(min(36, len(ws.T))):\n",
    "                    plt.subplot(6,6,i+1)\n",
    "                    # imshow_(model.get_weights()[0][i][:,:,0]+model.get_weights()[1][i])\n",
    "                    imshow_(np.squeeze(ws[:,:,:,i]).T)\n",
    "                    # Output weights at the first layer\n",
    "\n",
    "    print()\n",
    "    trial_metrics.print_scores()\n",
    "    trial_metrics.print_trials()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.74900398,  0.71186441,  0.67567568,  0.70750988,  0.68076923])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6807692307692308"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.24351263,  0.31457826,  2.50668168, ..., -2.82777572,\n",
       "         -3.10571742, -0.62007248],\n",
       "        [ 5.5147934 , -1.28239012,  2.42303205, ..., -2.19008303,\n",
       "         -1.86562991, -1.14939916],\n",
       "        [ 4.2265048 , -1.33588779,  1.9287039 , ..., -3.09149337,\n",
       "         -3.65799332, -3.99957395],\n",
       "        ..., \n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       [[ 5.7950983 , -1.61995947,  3.03088641, ...,  0.21895215,\n",
       "         -0.82384783, -0.59057939],\n",
       "        [ 3.75023055, -1.17448354,  4.14486551, ...,  4.00142002,\n",
       "         -1.74908257, -0.27602702],\n",
       "        [ 3.47163463, -0.89639378,  3.61994219, ...,  2.83434987,\n",
       "         -1.98891902, -0.83189869],\n",
       "        ..., \n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       [[ 3.54319763,  0.12254817,  4.3505497 , ...,  3.14978957,\n",
       "         -1.23136497,  0.54351819],\n",
       "        [ 2.89562869,  0.7640357 ,  4.03993416, ...,  2.7472403 ,\n",
       "         -1.01053202, -0.2045345 ],\n",
       "        [ 3.7469666 ,  0.53782386,  4.43863249, ...,  3.09529257,\n",
       "         -1.40868783, -0.02390432],\n",
       "        ..., \n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       ..., \n",
       "       [[-4.24716997,  3.19201922, -2.88252544, ..., -1.32046378,\n",
       "         -2.19939065, -0.00769815],\n",
       "        [-3.79273391,  3.46492648, -3.57052732, ..., -1.27638006,\n",
       "         -2.93491316,  2.09892654],\n",
       "        [-3.82607436,  3.76994896, -3.67747784, ..., -1.54700923,\n",
       "         -3.55176401,  1.88565195],\n",
       "        ..., \n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       [[-2.88046432,  4.58180237, -2.7463243 , ..., -2.33327723,\n",
       "         -3.50358009, -0.15959162],\n",
       "        [ 1.64226091,  3.51613832, -2.71243834, ..., -2.63981676,\n",
       "         -2.10697794, -0.3869442 ],\n",
       "        [ 1.8998611 ,  3.41724849, -2.4802897 , ..., -4.00865746,\n",
       "         -1.98987865, -2.63995385],\n",
       "        ..., \n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       [[ 1.615412  ,  1.02522814, -3.598171  , ..., -3.09197783,\n",
       "         -2.74786043, -1.19742262],\n",
       "        [ 2.81667542, -1.31446612, -4.65839529, ..., -5.50888872,\n",
       "         -0.44331169, -2.15854669],\n",
       "        [ 2.93243361, -0.05583981, -3.95589256, ..., -4.45197487,\n",
       "         -0.2925601 , -0.38663056],\n",
       "        ..., \n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 1, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf-ap]",
   "language": "python",
   "name": "conda-env-tf-ap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
